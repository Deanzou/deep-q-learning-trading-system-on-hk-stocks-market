{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../HKDailyStocksQuotes/0001.HK.csv\", index_col = 'Date')\n",
    "# data = pd.read_csv(\"0001.HK.csv\", index_col = 'Date')\n",
    "data.index = pd.to_datetime(data.index,  format=\"%Y%m%d\")\n",
    "# data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-np.inf, -0.1, -0.05, -0.03, 0, 0.03, 0.05, 0.1, np.inf]\n",
    "names = ['<-0.1', '-0.1--0.05', '-0.05--0.03', ' -0.03-0', '0-0.03', '0.03-0.05', '0.05-0.1', '>0.1']\n",
    "no_data_to_remove = 15\n",
    "\n",
    "train_ratio = 0.7\n",
    "\n",
    "\n",
    "def turning_points(array):\n",
    "    \"\"\" turning_points(array) -> min_indices, max_indices\n",
    "    Finds the turning points within an 1D array and returns the indices of the minimum and\n",
    "    maximum turning points in two separate lists.\n",
    "    \"\"\"\n",
    "    idx_max, idx_min = [], []\n",
    "    if len(array) < 3:\n",
    "        return idx_min, idx_max\n",
    "\n",
    "    NEUTRAL, RISING, FALLING = range(3)\n",
    "\n",
    "    def get_state(a, b):\n",
    "        if a < b: return RISING\n",
    "        if a > b: return FALLING\n",
    "        return NEUTRAL\n",
    "\n",
    "    ps = get_state(array[0], array[1])\n",
    "    begin = 1\n",
    "    for i in range(2, len(array)):\n",
    "        s = get_state(array[i - 1], array[i])\n",
    "        if s != NEUTRAL:\n",
    "            if ps != NEUTRAL and ps != s:\n",
    "                if s == FALLING:\n",
    "                    idx_max.append((begin + i - 1) // 2)\n",
    "                else:\n",
    "                    idx_min.append((begin + i - 1) // 2)\n",
    "            begin = i\n",
    "            ps = s\n",
    "    return idx_min, idx_max \n",
    "\n",
    "def create_turning_point_matrix_for_day_diff(data, day_diff, id_tp_array):\n",
    "    # shift the turning point array to certain day difference, with the close price of turning point \n",
    "    id_tp_array = pd.DataFrame({'max' : [int(i in id_tp_array) for i in range(len(data))]})\n",
    "    id_tp_array = id_tp_array.set_index(data.index)\n",
    "    idx_tp_shift = id_tp_array.shift(day_diff)\n",
    "    px_shift = data['Adj Close'].shift(day_diff)\n",
    "    # cal px diff of Tday's px and TP's px\n",
    "    px_diff = ((data['Adj Close'] - px_shift) / px_shift).mul(idx_tp_shift['max'], fill_value=0)\n",
    "    \n",
    "    \n",
    "    # binning and transform to one hot categorization\n",
    "    # fibonacci_bins = [-np.inf, -0.764, -0.618, -0.5, -0.382, 0, 0.382, 0.5, 0.618, 0.764, np.inf]\n",
    "    \n",
    "    px_diff_bin = pd.cut(px_diff, bins, labels=names)\n",
    "    px_diff_bin = pd.get_dummies(px_diff_bin)\n",
    "    px_diff_bin[px_diff==0] = 0 # px-diff==0 is matched into 1 bin, but it should be zero in all cols\n",
    "\n",
    "    return px_diff_bin\n",
    "\n",
    "def create_turning_point_3d_matrix(data):\n",
    "    if data is None:\n",
    "        return None, None\n",
    "    # create turning points series\n",
    "    idx_min, idx_max = turning_points(data['Adj Close'])\n",
    "\n",
    "    # remove the first 15 rows explicitly\n",
    "    max_matrix2 = create_turning_point_matrix_for_day_diff(data, 2, idx_max)[no_data_to_remove:]\n",
    "    max_matrix3 = create_turning_point_matrix_for_day_diff(data, 3, idx_max)[no_data_to_remove:]\n",
    "    max_matrix5 = create_turning_point_matrix_for_day_diff(data, 5, idx_max)[no_data_to_remove:]\n",
    "    max_matrix10 = create_turning_point_matrix_for_day_diff(data, 10, idx_max)[no_data_to_remove:]\n",
    "    max_matrix15 = create_turning_point_matrix_for_day_diff(data, 15, idx_max)[no_data_to_remove:]\n",
    "    \n",
    "\n",
    "    result_max = pd.concat([max_matrix2, max_matrix3, max_matrix5, max_matrix10, max_matrix15], keys=[2, 3, 5, 10, 15])\n",
    "    result_max.index = result_max.index.swaplevel(1, 0)\n",
    "    result_max = result_max.sort_index()\n",
    "    result_max.index.names = ['Date', 'DayDiff']\n",
    "    result_max.fillna(0)\n",
    "\n",
    "    # remove the first 15 rows explicitly\n",
    "    min_matrix2 = create_turning_point_matrix_for_day_diff(data, 2, idx_min)[no_data_to_remove:]\n",
    "    min_matrix3 = create_turning_point_matrix_for_day_diff(data, 3, idx_min)[no_data_to_remove:]\n",
    "    min_matrix5 = create_turning_point_matrix_for_day_diff(data, 5, idx_min)[no_data_to_remove:]\n",
    "    min_matrix10 = create_turning_point_matrix_for_day_diff(data, 10, idx_min)[no_data_to_remove:]\n",
    "    min_matrix15 = create_turning_point_matrix_for_day_diff(data, 15, idx_min)[no_data_to_remove:]\n",
    "\n",
    "    result_min = pd.concat([min_matrix2, min_matrix3, min_matrix5, min_matrix10, min_matrix15], keys=[2, 3, 5, 10, 15])\n",
    "    # rotate the matrix axes\n",
    "    result_min.index = result_min.index.swaplevel(1, 0)\n",
    "    result_min = result_min.sort_index()\n",
    "    result_min.index.names = ['Date', 'DayDiff']\n",
    "    result_min.fillna(0)\n",
    "\n",
    "    return result_max, result_min\n",
    "\n",
    "def create_technical_indicator_3d_matrix(data):\n",
    "    if data is None:\n",
    "        return None\n",
    "    high_low_diff = (data['High'] - data['Low']) / data['Low']\n",
    "    ma5_diff = (sma(data['Close'], 5) - data['Close']) / data['Close']\n",
    "    ma10_diff = (sma(data['Close'], 10) - data['Close']) / data['Close']\n",
    "    ma20_diff = (sma(data['Close'], 20) - data['Close']) / data['Close']\n",
    "\n",
    "    high_low_diff_bin = pd.cut(high_low_diff, bins, labels=names)\n",
    "    ma5_diff_bin = pd.cut(ma5_diff, bins, labels=names)\n",
    "    ma10_diff_bin = pd.cut(ma10_diff, bins, labels=names)\n",
    "    ma20_diff_bin = pd.cut(ma20_diff, bins, labels=names)\n",
    "\n",
    "    result_hl_diff = pd.get_dummies(high_low_diff_bin)\n",
    "    result_ma5_diff = pd.get_dummies(ma5_diff_bin)\n",
    "    result_ma10_diff = pd.get_dummies(ma10_diff_bin)\n",
    "    result_ma20_diff = pd.get_dummies(ma20_diff_bin)\n",
    "    result_hl_diff[high_low_diff == 0] = 0  # remove 0 value\n",
    "    result_ma5_diff[ma5_diff == 0] = 0  # remove 0 value\n",
    "    result_ma10_diff[ma10_diff == 0] = 0  # remove 0 value\n",
    "    result_ma20_diff[ma20_diff == 0] = 0  # remove 0 value\n",
    "    result_hl_diff = result_hl_diff[no_data_to_remove:]\n",
    "    result_ma5_diff = result_ma5_diff[no_data_to_remove:]\n",
    "    result_ma10_diff = result_ma10_diff[no_data_to_remove:]\n",
    "    result_ma20_diff = result_ma20_diff[no_data_to_remove:]\n",
    "\n",
    "    result_matrix = pd.concat([result_hl_diff, result_ma5_diff, result_ma10_diff, result_ma20_diff],\n",
    "                              keys=['hl_diff', 'ma5_diff', 'ma10_diff', 'ma20_diff'])\n",
    "    # rotate result matrix axes\n",
    "    result_matrix.index = result_matrix.index.swaplevel(1, 0)\n",
    "    result_matrix = result_matrix.sort_index()\n",
    "    result_matrix.index.names = ['Date', 'Indicator']\n",
    "\n",
    "    return result_matrix\n",
    "\n",
    "def sma(data, period=5):\n",
    "    return data.rolling(period).mean()\n",
    "\n",
    "def get_next_day(date, data):\n",
    "    # next row in data\n",
    "    next_index = data.index.get_loc(date)+1\n",
    "    if(next_index >= len(data.index)):\n",
    "        return None\n",
    "    else:\n",
    "        return data.index[data.index.get_loc(date)+1]\n",
    "    \n",
    "def enrich_market_data(data):\n",
    "    if data is None:\n",
    "        return\n",
    "\n",
    "    data['ma5'] = sma(data['Close'], 5)\n",
    "    data['rate_of_close'] = data['Close'].pct_change()\n",
    "    return data[no_data_to_remove:]\n",
    "\n",
    "def get_next_day(date, data):\n",
    "    # next row in data\n",
    "    next_index = data.index.get_loc(date) + 1\n",
    "    if next_index >= len(data.index):\n",
    "        return None\n",
    "    else:\n",
    "        return data.index[data.index.get_loc(date) + 1]\n",
    "    \n",
    "def clean_data(data):\n",
    "    if data is None:\n",
    "        return\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "def split_data_set_index(data):\n",
    "    train_split = int(len(data) * train_ratio)\n",
    "\n",
    "    train = data[:train_split].index\n",
    "    test = data[train_split:].index\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_min, idx_max = turning_points(data['Adj Close'])\n",
    "\n",
    "# plt.plot(data[:100].index, pd.Series(max_array)[:100]*30)\n",
    "# plt.plot(data['Adj Close'][:100], marker='o', markevery=idx_min)\n",
    "# plt.plot(data['Adj Close'][:100], marker='o', markevery=idx_max)\n",
    "# plt.ylabel('some numbers')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_data(data)                  \n",
    "turning_point_max, turning_point_min = create_turning_point_3d_matrix(data)\n",
    "technical_indicator_matrix = create_technical_indicator_3d_matrix(data)\n",
    "data = enrich_market_data(data)\n",
    "# result_max.groupby('DayDiff').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4782"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# technical_indicator_matrix[technical_indicator_matrix.isnull().any(axis=1)]\n",
    "assert len(data) == len(turning_point_max.index.levels[0])\n",
    "assert len(turning_point_max.index.levels[0]) == len(turning_point_min.index.levels[0])\n",
    "assert len(turning_point_min.index.levels[0]) == len(technical_indicator_matrix.index.levels[0])\n",
    "len(turning_point_max.index.levels[0])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Close, dtype: float64)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma20_diff = (sma(data['Close'], 20) - data['Close']) / data['Close']\n",
    "ma20_diff[ma20_diff==0]\n",
    "# max_matrix2 = create_turning_point_matrix_for_day_diff(data, 2, idx_max)\n",
    "# max_matrix2 = max_matrix2[15:]\n",
    "# max_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "        def __init__(self, date, value):\n",
    "            self.date = date\n",
    "            self.value = value\n",
    "            ''\n",
    "def get_buy_signal_states_by_date(date):\n",
    "    try:\n",
    "        tp_max = turning_point_max.loc[date]\n",
    "        tp_min = turning_point_min.loc[date]\n",
    "        tech_indicator = tech_indicator_matrix.loc[date]\n",
    "        s = np.concatenate((tp_max.values.flatten(), tp_min.values.flatten(), tech_indicator.values.flatten()),\n",
    "                           axis=0)\n",
    "        state = State(date, s)\n",
    "        print(\"generated buySignalStates, date \" + str(date))\n",
    "        return state\n",
    "    except KeyError:\n",
    "        print(\"ERROR getting buy signal state for date \" + str(date))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laikasin93/.local/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.loc[data.sample().index.values[0]]\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoder.fit(np.array([i for i in range(7)]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]]\n",
      "[[6.]]\n"
     ]
    }
   ],
   "source": [
    "# len(one_hot_encoder.active_features_)\n",
    "# one_hot_encoder.transform([[1]])\n",
    "# one_hot_encoder.transform([[0]])\n",
    "action = one_hot_encoder.transform([[6]])\n",
    "inverse_action = one_hot_encoder.inverse_transform(action)\n",
    "print(action)\n",
    "print(inverse_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_map = {-3: 0,\n",
    "              -2: 1,\n",
    "              -1: 2,\n",
    "              0: 3,\n",
    "              1: 4,\n",
    "              2: 5,\n",
    "              3: 6}\n",
    "random.choice(list(action_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = enrich_market_data(data)\n",
    "# data[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data_set_index(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-12T00:00:00.000000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-13 00:00:00')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.index.get_loc(test[0])\n",
    "# date.index[0]\n",
    "day = pd.Series(train).sample().values[0]\n",
    "print(day)\n",
    "get_next_day(day,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
